{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current shape:  (401, 25)\n",
      "Removed Entry:  13\n",
      "Removed Entry:  17\n",
      "Removed Entry:  21\n",
      "Removed Entry:  23\n",
      "Removed Entry:  28\n",
      "Removed Entry:  30\n",
      "Removed Entry:  34\n",
      "Removed Entry:  41\n",
      "Removed Entry:  55\n",
      "Removed Entry:  57\n",
      "Removed Entry:  59\n",
      "Removed Entry:  64\n",
      "Removed Entry:  67\n",
      "Removed Entry:  72\n",
      "Removed Entry:  78\n",
      "Removed Entry:  82\n",
      "Removed Entry:  85\n",
      "Removed Entry:  86\n",
      "Removed Entry:  104\n",
      "Removed Entry:  109\n",
      "Removed Entry:  113\n",
      "Removed Entry:  116\n",
      "Removed Entry:  119\n",
      "Removed Entry:  122\n",
      "Removed Entry:  125\n",
      "Removed Entry:  138\n",
      "Removed Entry:  142\n",
      "Removed Entry:  148\n",
      "Removed Entry:  151\n",
      "Removed Entry:  156\n",
      "Removed Entry:  161\n",
      "Removed Entry:  165\n",
      "Removed Entry:  166\n",
      "Removed Entry:  188\n",
      "Removed Entry:  192\n",
      "Removed Entry:  194\n",
      "Removed Entry:  197\n",
      "Removed Entry:  201\n",
      "Removed Entry:  202\n",
      "Removed Entry:  203\n",
      "Removed Entry:  205\n",
      "Removed Entry:  208\n",
      "Removed Entry:  209\n",
      "Removed Entry:  211\n",
      "Removed Entry:  215\n",
      "Removed Entry:  222\n",
      "Removed Entry:  228\n",
      "Removed Entry:  231\n",
      "Removed Entry:  232\n",
      "Removed Entry:  236\n",
      "Removed Entry:  238\n",
      "Removed Feature:  5\n",
      "The New shape:  (349, 23)\n",
      "Missing Values filled with Averages\n",
      "\n",
      "SVC Linear F-Measure 0.9855072463768115\n",
      "SVC RBG F-Measure 0.33333333333333337\n",
      "Random Forest Classifier F-Measure 1.0\n"
     ]
    }
   ],
   "source": [
    "#SVC by Daniel McDonough\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import operator\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def fmeasure(con_matrix):\n",
    "\n",
    "    if con_matrix.shape == (1,1):\n",
    "        TP = con_matrix[0,0]\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "    else:\n",
    "        #note TP and TN are switched here becuase we are testing Notckd\n",
    "        TP = con_matrix[1,1]\n",
    "        FN = con_matrix[0,1]\n",
    "\n",
    "        FP = con_matrix[1,0]\n",
    "\n",
    "        TN = con_matrix[0,0]\n",
    "\n",
    "    PRE = TP/(TP+FP)\n",
    "    REC = TP/(TP+FN)\n",
    "    if math.isnan(PRE):\n",
    "        PRE = 0\n",
    "    if math.isnan(REC):\n",
    "        REC = 0\n",
    "\n",
    "    fmeasure = 2*((PRE*REC) / (PRE+REC))\n",
    "\n",
    "    if math.isnan(fmeasure):\n",
    "        fmeasure = 0\n",
    "\n",
    "    return fmeasure\n",
    "\n",
    "\n",
    "\n",
    "#function that cleans empty columns in the dataset and major missing columns\n",
    "def resize_data(data):\n",
    "\n",
    "    print(\"The current shape: \",data.shape)\n",
    "    #columns_titles = data[0,:] #save the first row\n",
    "    data = np.delete(data, 0, 0) #delete first row\n",
    "    #print(columns_titles)\n",
    "\n",
    "    nullcount_row = [0]*len(data[:,0]) #number of columns\n",
    "    nullcount_col = [0]*len(data[1,:]) #number of rows\n",
    "\n",
    "    #remove bad data entries\n",
    "    for i in range(len(data[:,0])):\n",
    "        for j in range(len(data[0,:])):\n",
    "            data[i,j] = re.sub('\\s+', '', data[i,j]) #remove special char if that exist\n",
    "            if data[i,j] == \"NA\" or data[i,j] == \"\":\n",
    "                nullcount_row[i] += 1 #get a count of NA features per data entry\n",
    "\n",
    "    shaped_data = []\n",
    "    empty_thresh = len(data[0,:])*0.25 #threshold of empty datapoint to remove the entry\n",
    "\n",
    "    #if a data entry is missing more than 25% of features then remove it...\n",
    "    for k in range(len(nullcount_row)):\n",
    "        if not nullcount_row[k] >= empty_thresh:\n",
    "            shaped_data.append(data[k]) #append good data\n",
    "        else:\n",
    "            print(\"Removed Entry: \", k)\n",
    "    shaped_data = np.array(shaped_data)\n",
    "    #print(shaped_data.shape)\n",
    "    #print(shaped_data)\n",
    "\n",
    "\n",
    "    #remove bad features\n",
    "    for j in range(len(shaped_data[0,:])):\n",
    "        for i in range(len(shaped_data[:,0])):\n",
    "            if shaped_data[i,j] == \"NA\" or shaped_data[i,j] == \"\":\n",
    "                nullcount_col[j] += 1 #get a count of NA features per data entry\n",
    "\n",
    "    clean_data = []\n",
    "    #print(type(clean_data))\n",
    "    empty_thresh = len(data[:,0])*0.25 #threshold of empty datapoints to remove the feature\n",
    "    #print(empty_thresh)\n",
    "\n",
    "    #if a feature is missing more than 25% of data then remove it...\n",
    "    for k in range(len(nullcount_col)):\n",
    "        if not nullcount_col[k] >= empty_thresh:\n",
    "            clean_data.append(shaped_data[:,k]) #append good data\n",
    "        else:\n",
    "            print(\"Removed Feature: \", k)\n",
    "    clean_data = np.array(clean_data).T\n",
    "    #print(clean_data.shape)\n",
    "    lastcol = clean_data.shape[1]-1\n",
    "    #print(\"Last column: \",lastcol)\n",
    "    labels = clean_data[:,lastcol]#get the labels\n",
    "    clean_data = np.delete(clean_data, lastcol, 1) #delete the labels\n",
    "\n",
    "    #print(clean_data)\n",
    "\n",
    "    return clean_data,labels\n",
    "\n",
    "\n",
    "\n",
    "#function that gets the mean value dispite the type of data\n",
    "def getmean(good_data):\n",
    "    #avg = 0\n",
    "    good_data = list(map(float, good_data)) #turn strings into floats\n",
    "    total = sum(good_data)\n",
    "    avg = total / len(good_data)\n",
    "    #print(good_data)\n",
    "    #print(good_data.shape)\n",
    "\n",
    "    return avg\n",
    "\n",
    "#function that returns the avg and list of missing data points\n",
    "def mean_missing(data,col):\n",
    "\n",
    "    good_data = [] #used to calculate the sum / average\n",
    "    bad_data = [] #list of locations to data points with NA\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, col] == '' or data[i, col] == \"NA\":\n",
    "            bad_data.append((i, col))\n",
    "        else:\n",
    "            good_data.append(data[i, col])\n",
    "    #print(col)\n",
    "    mean = getmean(good_data)\n",
    "    return mean,bad_data\n",
    "\n",
    "def discrete_to_num(data,col):\n",
    "    good_data = []  # used to calculate the sum / average\n",
    "    bad_data = [] #list of locations to data points with NA\n",
    "    #get the good data in the column\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, col] == '' or data[i, col] == \"NA\":\n",
    "            bad_data.append((i, col))\n",
    "            good_data.append(data[i, col])\n",
    "        else:\n",
    "            good_data.append(data[i, col])\n",
    "\n",
    "    unique = list(set(good_data)) # set of unique values\n",
    "    unique.remove(\"NA\")\n",
    "    val = list(range(len(unique))) #values corresponding to each unique value\n",
    "    #print(unique)\n",
    "    # print(val)\n",
    "    #convert good_data into ints\n",
    "    for j in range(len(good_data)):\n",
    "        for k in range(len(unique)):\n",
    "            if good_data[j] == unique[k]:\n",
    "                good_data[j] = val[k]\n",
    "                break;\n",
    "    unique = good_data\n",
    "\n",
    "    unique= list(filter(lambda a: a != \"NA\", unique))\n",
    "\n",
    "    #print(val)\n",
    "    # print(col)\n",
    "    # print(good_data)\n",
    "    mean = getmean(unique)\n",
    "    return mean, bad_data,good_data\n",
    "\n",
    "#function the replaces missing data with\n",
    "def calcdata(data):\n",
    "    for i in range(data.shape[1]):\n",
    "\n",
    "        if isfloat(data[5,i]): #alter the numerical data\n",
    "            avg, list = mean_missing(data,i)\n",
    "            for j in range(len(list)): #replace NA\n",
    "                xy = list[j]\n",
    "                data[xy[0], xy[1]] = avg\n",
    "        else:\n",
    "            #change discrete values to numbers\n",
    "            avg, list,data[:,i] = discrete_to_num(data,i)\n",
    "            for j in range(len(list)): #replace NA\n",
    "                xy = list[j]\n",
    "                data[xy[0], xy[1]] = avg\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanupdata(data):\n",
    "    shaped_data,labels = resize_data(data) #delete bad data\n",
    "    print(\"The New shape: \", shaped_data.shape)\n",
    "    avg_data = calcdata(shaped_data)\n",
    "    print(\"Missing Values filled with Averages\")\n",
    "    avg_data = np.delete(avg_data, 0, 0) #delete first row (aka feature names)\n",
    "    #print(avg_data)\n",
    "    return avg_data,labels\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    fileobject = np.loadtxt(\"chronic_kidney_disease_full.csv\", delimiter=\",\",dtype='str')\n",
    "\n",
    "\n",
    "    data,labels = cleanupdata(fileobject)\n",
    "    #print(data)\n",
    "    training_size = int(math.floor(len(data[:,0])*0.8)) # 80% training size\n",
    "    #print(training_size)\n",
    "\n",
    "    training = data[:training_size] #training data\n",
    "    validation = data[training_size:] #vaildation data\n",
    "\n",
    "    training_labels = labels[:training_size]\n",
    "    true_labels = labels[training_size+1:]\n",
    "\n",
    "    # print(len(validation))\n",
    "    # print(len(true_labels))\n",
    "    clf = SVC(kernel='linear').fit(training,training_labels)\n",
    "    #print(\"Accuracy: \",clf.score(training, training_labels))\n",
    "    pred = clf.predict(validation)\n",
    "    con_matrix = confusion_matrix(true_labels, pred)\n",
    "   # print(\"SVC Linear Confusion Matrix: \\n\",con_matrix)\n",
    "    #print(\"Linear Kernel F1 Score: \",f1_score(true_labels, pred))\n",
    "    print(\"\\nSVC Linear F-Measure\",fmeasure(con_matrix))\n",
    "\n",
    "\n",
    "    rbf = SVC(kernel='rbf',gamma=\"scale\").fit(training, training_labels)\n",
    "    #print(rbf.score(training, training_labels))\n",
    "    pred = rbf.predict(validation)\n",
    "    con_matrix = confusion_matrix(true_labels, pred)\n",
    "    #print(\"SVC RBF Confusion Matrix: \\n\",con_matrix)\n",
    "   # print(\"RBF Kernal F1 Score: \", f1_score(true_labels, pred))\n",
    "    print(\"SVC RBG F-Measure\",fmeasure(con_matrix))\n",
    "\n",
    "\n",
    "\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(training,training_labels)\n",
    "    #print(rfc.score(training, training_labels))\n",
    "    pred = rfc.predict(validation)\n",
    "   # print(\"Random Forest Classifier F1 Score: \", f1_score(true_labels, pred))\n",
    "    con_matrix = confusion_matrix(true_labels, pred)\n",
    "    #print(\"Random Forest Classifier Confusion Matrix: \\n\",con_matrix)\n",
    "    print(\"Random Forest Classifier F-Measure\",fmeasure(con_matrix))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
