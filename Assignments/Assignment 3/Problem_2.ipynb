{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current shape:  (401, 25)\n",
      "Removed Entry:  13\n",
      "Removed Entry:  17\n",
      "Removed Entry:  21\n",
      "Removed Entry:  23\n",
      "Removed Entry:  28\n",
      "Removed Entry:  30\n",
      "Removed Entry:  34\n",
      "Removed Entry:  41\n",
      "Removed Entry:  55\n",
      "Removed Entry:  57\n",
      "Removed Entry:  59\n",
      "Removed Entry:  64\n",
      "Removed Entry:  67\n",
      "Removed Entry:  72\n",
      "Removed Entry:  78\n",
      "Removed Entry:  82\n",
      "Removed Entry:  85\n",
      "Removed Entry:  86\n",
      "Removed Entry:  104\n",
      "Removed Entry:  109\n",
      "Removed Entry:  113\n",
      "Removed Entry:  116\n",
      "Removed Entry:  119\n",
      "Removed Entry:  122\n",
      "Removed Entry:  125\n",
      "Removed Entry:  138\n",
      "Removed Entry:  142\n",
      "Removed Entry:  148\n",
      "Removed Entry:  151\n",
      "Removed Entry:  156\n",
      "Removed Entry:  161\n",
      "Removed Entry:  165\n",
      "Removed Entry:  166\n",
      "Removed Entry:  188\n",
      "Removed Entry:  192\n",
      "Removed Entry:  194\n",
      "Removed Entry:  197\n",
      "Removed Entry:  201\n",
      "Removed Entry:  202\n",
      "Removed Entry:  203\n",
      "Removed Entry:  205\n",
      "Removed Entry:  208\n",
      "Removed Entry:  209\n",
      "Removed Entry:  211\n",
      "Removed Entry:  215\n",
      "Removed Entry:  222\n",
      "Removed Entry:  228\n",
      "Removed Entry:  231\n",
      "Removed Entry:  232\n",
      "Removed Entry:  236\n",
      "Removed Entry:  238\n",
      "Removed Feature:  5\n",
      "The New shape:  (349, 23)\n",
      "Missing Values filled with Averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:169: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logistic Regression by Daniel Mcdonough\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from scipy.optimize import fmin_bfgs\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import operator\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "\n",
    "#logR = LogisticRegression(C=1., solver='lbfgs')\n",
    "def fmeasure(con_matrix):\n",
    "\n",
    "    if con_matrix.shape == (1,1):\n",
    "        TP = con_matrix[0,0]\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "    else:\n",
    "        #note TP and TN are switched here becuase we are testing Notckd\n",
    "        TP = con_matrix[0,0]\n",
    "        FN = con_matrix[1,0]\n",
    "\n",
    "        FP = con_matrix[0,1]\n",
    "\n",
    "        TN = con_matrix[1,1]\n",
    "\n",
    "    PRE = TP/(TP+FP)\n",
    "    REC = TP/(TP+FN)\n",
    "    if math.isnan(PRE):\n",
    "        PRE = 0\n",
    "    if math.isnan(REC):\n",
    "        REC = 0\n",
    "\n",
    "    fmeasure = 2*((PRE*REC) / (PRE+REC))\n",
    "\n",
    "    if math.isnan(fmeasure):\n",
    "        fmeasure = 0\n",
    "\n",
    "    return fmeasure\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, data, labels, regularized, alpha=0.01, num_iters=300, normalization='norm'):\n",
    "        self.normalization_mode = normalization\n",
    "        self.regularized = regularized\n",
    "        self.num_iters = num_iters\n",
    "        self.alpha = alpha\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self, data, Olabels, unique_classes):\n",
    "\n",
    "        #print('training....')\n",
    "        regularized = self.regularized\n",
    "        # print 'train regularized', regularized\n",
    "\n",
    "        num_iters = self.num_iters\n",
    "        m, n = data.shape\n",
    "\n",
    "        # map labels to program friendly labels\n",
    "        labels = np.zeros(Olabels.shape)\n",
    "\n",
    "        uniq_Olabel_names = np.unique(Olabels)\n",
    "\n",
    "        uniq_label_list = range(len(uniq_Olabel_names))\n",
    "\n",
    "        for each in zip(uniq_Olabel_names, uniq_label_list):\n",
    "            o_label_name = each[0]\n",
    "            new_label_name = each[1]\n",
    "            labels[np.where(Olabels == o_label_name)] = new_label_name\n",
    "\n",
    "        labels = labels.reshape((len(labels), 1))\n",
    "\n",
    "\n",
    "        # if num_classes = 2, then Thetas will contain only 1 Theta\n",
    "        # if num_classes >2, then Thetas will contain num_classes of Thetas.\n",
    "\n",
    "\n",
    "\n",
    "        Init_Thetas = []  # to hold initial values of theta\n",
    "\n",
    "        Thetas = []  # to hold final values of theta to return\n",
    "\n",
    "        # if (num_classes == 2):\n",
    "        theta_init = np.zeros((n, 1))\n",
    "        Init_Thetas.append(theta_init)\n",
    "\n",
    "\n",
    "        init_theta = Init_Thetas[0]\n",
    "\n",
    "        new_theta, final_cost = self.computeGradient(data, labels, init_theta)\n",
    "\n",
    "\n",
    "        Thetas.append(new_theta)\n",
    "\n",
    "\n",
    "        # elif (num_classes > 2):\n",
    "        #     for eachInitTheta in range(num_classes):\n",
    "        #         theta_init = np.zeros((n, 1))\n",
    "        #         Init_Thetas.append(theta_init)\n",
    "        #         pass\n",
    "        #\n",
    "        #     for eachClass in range(num_classes):\n",
    "        #         # load data local of the init_theta\n",
    "        #         # +ve class is 1 and rest are zeros\n",
    "        #         # its a one vs all classifier\n",
    "        #\n",
    "        #         local_labels = np.zeros(labels.shape)\n",
    "        #\n",
    "        #         local_labels[np.where(labels == eachClass)] = 1\n",
    "        #\n",
    "        #         # assert to make sure that its true\n",
    "        #\n",
    "        #         # print eachClass\n",
    "        #         # print Init_Thetas\n",
    "        #         init_theta = Init_Thetas[eachClass]\n",
    "        #\n",
    "        #         new_theta, final_cost = self.computeGradient(data, local_labels, init_theta)\n",
    "        #         # print final_cost\n",
    "        #         Thetas.append(new_theta)\n",
    "        #         Cost_Thetas.append(final_cost)\n",
    "\n",
    "        return Thetas\n",
    "\n",
    "    def classify(self, data, Thetas):\n",
    "\n",
    "        # since it is a one values all classifier, load all classifiers and pick most likely\n",
    "        # i.e. which gives max value for sigmoid(X*theta)\n",
    "        #print(len(Thetas))\n",
    "        #print((Thetas))\n",
    "        if (len(Thetas) >1):\n",
    "            mvals = []\n",
    "            for eachTheta in Thetas:\n",
    "                mvals.append(self.sigmoidCalc(np.dot(data, eachTheta)))\n",
    "\n",
    "                pass\n",
    "            return mvals.index(max(mvals)) + 1\n",
    "\n",
    "        elif (len(Thetas) == 1):\n",
    "            # either is close to zero or 1\n",
    "            # if more than 0.5 classify as 1 and if less than 0.5 classify as 0\n",
    "            # print data\n",
    "            # print Thetas[0]\n",
    "            # print self.sigmoidCalc(np.dot(data, Thetas[0]))\n",
    "            a = self.sigmoidCalc(np.dot(data, Thetas[0]))\n",
    "            #print(a)\n",
    "            cval = np.round(a)\n",
    "\n",
    "            #print('classification output: ', cval)\n",
    "            return cval\n",
    "\n",
    "    def sigmoidCalc(self, data):\n",
    "\n",
    "        # if(len(data.flatten()) == 1 ):\n",
    "        # \tdata = data.reshape((1,1))\n",
    "\n",
    "        # data = np.array(data, dtype=np.longdouble)\n",
    "        g = 1 / (1 + np.exp(-data))\n",
    "\n",
    "        return g\n",
    "\n",
    "    def computeCost(self, data, labels, init_theta):\n",
    "\n",
    "        llambda = self.regularized\n",
    "\n",
    "        m, n = data.shape\n",
    "\n",
    "        theta2 = init_theta[range(1, init_theta.shape[0]), :]\n",
    "\n",
    "        if (self.normalization_mode == \"norm\"):\n",
    "            regularized_parameter = np.dot(llambda / (2 * m), np.sum(np.abs(theta2)))\n",
    "        else:\n",
    "            regularized_parameter = np.dot(llambda / (2 * m), np.sum(theta2 * theta2))\n",
    "\n",
    "\n",
    "\n",
    "        a = self.sigmoidCalc(np.dot(data, init_theta))\n",
    "\n",
    "        #print(L)\n",
    "        J = (-1.0 / m) * (np.sum(np.log(a) * labels + (np.log(1 - a) * (1 - labels))))\n",
    "\n",
    "        J = J + regularized_parameter\n",
    "\n",
    "        return J\n",
    "\n",
    "    def computeGradient(self, data, labels, init_theta):\n",
    "        alpha = self.alpha\n",
    "        num_iters = self.num_iters\n",
    "        m, n = data.shape\n",
    "        llambda = self.regularized\n",
    "\n",
    "\n",
    "        #print(num_iters)\n",
    "        for eachIteration in range(num_iters):\n",
    "            cost = self.computeCost(data, labels, init_theta)\n",
    "\n",
    "            # compute gradient\n",
    "\n",
    "            B = self.sigmoidCalc(np.dot(data, init_theta) - labels)\n",
    "\n",
    "            A = (1 / m) * np.transpose(data)\n",
    "\n",
    "            grad = np.dot(A, B)\n",
    "\n",
    "            A = (self.sigmoidCalc(np.dot(data, init_theta)) - labels)\n",
    "            B = data[:, 0].reshape((data.shape[0], 1))\n",
    "\n",
    "            grad[0] = (1 / m) * np.sum(A * B)\n",
    "\n",
    "            A = (self.sigmoidCalc(np.dot(data, init_theta)) - labels)\n",
    "            B = (data[:, range(1, n)])\n",
    "\n",
    "            for i in range(1, len(grad)):\n",
    "                A = (self.sigmoidCalc(np.dot(data, init_theta)) - labels)\n",
    "                B = (data[:, i].reshape((data[:, i].shape[0], 1)))\n",
    "                grad[i] = (1 / m) * np.sum(A * B) + ((llambda / m) * init_theta[i])\n",
    "\n",
    "            init_theta = init_theta + (np.dot((alpha / m), grad))\n",
    "            #print(init_theta)\n",
    "        return init_theta, cost\n",
    "\n",
    "    def mapper(self):\n",
    "        return None\n",
    "\n",
    "\n",
    "def numerical_labels(labels):\n",
    "    unique = list(set(labels))  # set of unique values\n",
    "    val = list(range(len(unique)))  # values corresponding to each unique value\n",
    "    for j in range(len(labels)):\n",
    "        for k in range(len(unique)):\n",
    "            if labels[j] == unique[k]:\n",
    "                labels[j] = val[k]\n",
    "                break;\n",
    "\n",
    "    return labels\n",
    "\n",
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def fmeasure(con_matrix):\n",
    "\n",
    "    if con_matrix.shape == (1,1):\n",
    "        TP = con_matrix[0,0]\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "    else:\n",
    "        #note TP and TN are switched here becuase we are testing Notckd\n",
    "        TP = con_matrix[1,1]\n",
    "        FN = con_matrix[0,1]\n",
    "\n",
    "        FP = con_matrix[1,0]\n",
    "\n",
    "        TN = con_matrix[0,0]\n",
    "\n",
    "    PRE = TP/(TP+FP)\n",
    "    REC = TP/(TP+FN)\n",
    "    if math.isnan(PRE):\n",
    "        PRE = 0\n",
    "    if math.isnan(REC):\n",
    "        REC = 0\n",
    "\n",
    "    fmeasure = 2*((PRE*REC) / (PRE+REC))\n",
    "\n",
    "    if math.isnan(fmeasure):\n",
    "        fmeasure = 0\n",
    "\n",
    "    return fmeasure\n",
    "\n",
    "\n",
    "\n",
    "#function that cleans empty columns in the dataset and major missing columns\n",
    "def resize_data(data):\n",
    "\n",
    "    print(\"The current shape: \",data.shape)\n",
    "    #columns_titles = data[0,:] #save the first row\n",
    "    data = np.delete(data, 0, 0) #delete first row\n",
    "    #print(columns_titles)\n",
    "\n",
    "    nullcount_row = [0]*len(data[:,0]) #number of columns\n",
    "    nullcount_col = [0]*len(data[1,:]) #number of rows\n",
    "\n",
    "    #remove bad data entries\n",
    "    for i in range(len(data[:,0])):\n",
    "        for j in range(len(data[0,:])):\n",
    "            data[i,j] = re.sub('\\s+', '', data[i,j]) #remove special char if that exist\n",
    "            if data[i,j] == \"NA\" or data[i,j] == \"\":\n",
    "                nullcount_row[i] += 1 #get a count of NA features per data entry\n",
    "\n",
    "    shaped_data = []\n",
    "    empty_thresh = len(data[0,:])*0.25 #threshold of empty datapoint to remove the entry\n",
    "\n",
    "    #if a data entry is missing more than 25% of features then remove it...\n",
    "    for k in range(len(nullcount_row)):\n",
    "        if not nullcount_row[k] >= empty_thresh:\n",
    "            shaped_data.append(data[k]) #append good data\n",
    "        else:\n",
    "            print(\"Removed Entry: \", k)\n",
    "    shaped_data = np.array(shaped_data)\n",
    "    #print(shaped_data.shape)\n",
    "    #print(shaped_data)\n",
    "\n",
    "\n",
    "    #remove bad features\n",
    "    for j in range(len(shaped_data[0,:])):\n",
    "        for i in range(len(shaped_data[:,0])):\n",
    "            if shaped_data[i,j] == \"NA\" or shaped_data[i,j] == \"\":\n",
    "                nullcount_col[j] += 1 #get a count of NA features per data entry\n",
    "\n",
    "    clean_data = []\n",
    "    #print(type(clean_data))\n",
    "    empty_thresh = len(data[:,0])*0.25 #threshold of empty datapoints to remove the feature\n",
    "    #print(empty_thresh)\n",
    "\n",
    "    #if a feature is missing more than 25% of data then remove it...\n",
    "    for k in range(len(nullcount_col)):\n",
    "        if not nullcount_col[k] >= empty_thresh:\n",
    "            clean_data.append(shaped_data[:,k]) #append good data\n",
    "        else:\n",
    "            print(\"Removed Feature: \", k)\n",
    "    clean_data = np.array(clean_data).T\n",
    "    #print(clean_data.shape)\n",
    "    lastcol = clean_data.shape[1]-1\n",
    "    #print(\"Last column: \",lastcol)\n",
    "    labels = clean_data[:,lastcol]#get the labels\n",
    "    clean_data = np.delete(clean_data, lastcol, 1) #delete the labels\n",
    "\n",
    "    #print(clean_data)\n",
    "\n",
    "    return clean_data,labels\n",
    "\n",
    "\n",
    "\n",
    "#function that gets the mean value dispite the type of data\n",
    "def getmean(good_data):\n",
    "    #avg = 0\n",
    "    good_data = list(map(float, good_data)) #turn strings into floats\n",
    "    total = sum(good_data)\n",
    "    avg = total / len(good_data)\n",
    "    #print(good_data)\n",
    "    #print(good_data.shape)\n",
    "\n",
    "    return avg\n",
    "\n",
    "#function that returns the avg and list of missing data points\n",
    "def mean_missing(data,col):\n",
    "\n",
    "    good_data = [] #used to calculate the sum / average\n",
    "    bad_data = [] #list of locations to data points with NA\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, col] == '' or data[i, col] == \"NA\":\n",
    "            bad_data.append((i, col))\n",
    "        else:\n",
    "            good_data.append(data[i, col])\n",
    "    #print(col)\n",
    "    mean = getmean(good_data)\n",
    "    return mean,bad_data\n",
    "\n",
    "def discrete_to_num(data,col):\n",
    "    good_data = []  # used to calculate the sum / average\n",
    "    bad_data = [] #list of locations to data points with NA\n",
    "    #get the good data in the column\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, col] == '' or data[i, col] == \"NA\":\n",
    "            bad_data.append((i, col))\n",
    "            good_data.append(data[i, col])\n",
    "        else:\n",
    "            good_data.append(data[i, col])\n",
    "\n",
    "    unique = list(set(good_data)) # set of unique values\n",
    "    unique.remove(\"NA\")\n",
    "    val = list(range(len(unique))) #values corresponding to each unique value\n",
    "    #print(unique)\n",
    "    # print(val)\n",
    "    #convert good_data into ints\n",
    "    for j in range(len(good_data)):\n",
    "        for k in range(len(unique)):\n",
    "            if good_data[j] == unique[k]:\n",
    "                good_data[j] = val[k]\n",
    "                break;\n",
    "    unique = good_data\n",
    "\n",
    "    unique= list(filter(lambda a: a != \"NA\", unique))\n",
    "\n",
    "    #print(val)\n",
    "    # print(col)\n",
    "    # print(good_data)\n",
    "    mean = getmean(unique)\n",
    "    return mean, bad_data,good_data\n",
    "\n",
    "#function the replaces missing data with\n",
    "def calcdata(data):\n",
    "    for i in range(data.shape[1]):\n",
    "\n",
    "        if isfloat(data[5,i]): #alter the numerical data\n",
    "            avg, list = mean_missing(data,i)\n",
    "            for j in range(len(list)): #replace NA\n",
    "                xy = list[j]\n",
    "                data[xy[0], xy[1]] = avg\n",
    "        else:\n",
    "            #change discrete values to numbers\n",
    "            avg, list,data[:,i] = discrete_to_num(data,i)\n",
    "            for j in range(len(list)): #replace NA\n",
    "                xy = list[j]\n",
    "                data[xy[0], xy[1]] = avg\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanupdata(data):\n",
    "    shaped_data,labels = resize_data(data) #delete bad data\n",
    "    print(\"The New shape: \", shaped_data.shape)\n",
    "    avg_data = calcdata(shaped_data)\n",
    "    print(\"Missing Values filled with Averages\")\n",
    "    avg_data = np.delete(avg_data, 0, 0) #delete first row (aka feature names)\n",
    "    #print(avg_data)\n",
    "    return avg_data,labels\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    fileobject = np.loadtxt(\"./chronic_kidney_disease_full.csv\", delimiter=\",\", dtype='str')\n",
    "\n",
    "    data, labels = cleanupdata(fileobject)\n",
    "    # print(data)\n",
    "    labels = numerical_labels(labels)\n",
    "    data = np.asfarray(data, float)\n",
    "    labels = np.asfarray(labels, float)\n",
    "    np.set_printoptions(threshold=np.nan)\n",
    "    training_size = int(math.floor(len(data[:, 0]) * 0.8))  # 80% training size\n",
    "    # print(training_size)\n",
    "\n",
    "    training = data[:training_size]  # training data\n",
    "    validation = data[training_size:]  # vaildation data\n",
    "\n",
    "    training_labels = labels[:training_size]\n",
    "    true_labels = labels[training_size+1:]\n",
    "    true_labels.flatten()\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    # dataset = pd.read_csv('ecommerce_data.csv')\n",
    "\n",
    "\n",
    "    norm_fm = []\n",
    "    std_fm = []\n",
    "\n",
    "    #\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Fmeasure')\n",
    "    plt.xlim([-2,4])\n",
    "    plt.grid(True)\n",
    "    lambda_range = [-2,-1,0,1,2,3,4]\n",
    "    #print(true_labels)\n",
    "    for i in range(-2,5):\n",
    "        #print(i)\n",
    "\n",
    "        lr1 = LogisticRegression(training, training_labels, i, 0.2, 1, normalization='norm')\n",
    "        learntParameters = lr1.train(training, training_labels, np.unique(training_labels))\n",
    "\n",
    "        Pred_labels = lr1.classify(validation,learntParameters)\n",
    "        #print(Pred_labels)\n",
    "\n",
    "\n",
    "        con_matrix = confusion_matrix(true_labels, Pred_labels)\n",
    "        #print(con_matrix)\n",
    "        #print(\"MODE: Norm F-Measure\", fmeasure(con_matrix))\n",
    "        norm_fm.append(fmeasure(con_matrix))\n",
    "\n",
    "\n",
    "\n",
    "        lr2 = LogisticRegression(training, training_labels, i, 0.2, 1, normalization='std')\n",
    "        learntParameters = lr2.train(training, training_labels, np.unique(training_labels))\n",
    "\n",
    "        Pred_labels = lr2.classify(validation, learntParameters)\n",
    "        # print(Pred_labels)\n",
    "        # print(true_labels)\n",
    "        con_matrix = confusion_matrix(true_labels, Pred_labels)\n",
    "\n",
    "        #print(con_matrix)\n",
    "        #print(\"MODE: STD F-Measure\", fmeasure(con_matrix))\n",
    "\n",
    "        std_fm.append(fmeasure(con_matrix))\n",
    "\n",
    "\n",
    "        #plt.plot(fmeasure(con_matrix),i)\n",
    "\n",
    "\n",
    "    #plot Norm\n",
    "    plt.plot(lambda_range,norm_fm,label=\"Normal\",c=\"r\" )\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #plot STD\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Fmeasure')\n",
    "    plt.xlim([-2,4])\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.plot(lambda_range,std_fm,label=\"Std\",c=\"b\" )\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #this was for comparison\n",
    "    # logR.fit(training, training_labels)\n",
    "    # pred = logR.predict(validation)\n",
    "    # print(pred)\n",
    "    # print(true_labels)\n",
    "    # con_matrix = confusion_matrix(true_labels, pred)\n",
    "    # print(con_matrix)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
